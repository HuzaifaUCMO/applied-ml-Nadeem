{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84345985",
   "metadata": {},
   "source": [
    "# Lab 2 â€“ Titanic Data Exploration and Splitting\n",
    "### *Huzaifa Nadeem*\n",
    "### *03-21-2025*\n",
    "\n",
    "## Introduction\n",
    "In this lab, we will explore the Titanic dataset and prepare it for machine learning. We will:\n",
    "1. Import and inspect the dataset\n",
    "2. Visualize data patterns\n",
    "3. Handle missing values\n",
    "4. Engineer new features\n",
    "5. Select features and target\n",
    "6. Split the data using both basic and stratified methods\n",
    "\n",
    "We will **not** publish or share any Howell dataset solution. Just using it as a guidance.\n",
    "Everything is done locally and then pushed to our GitHub repository.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb47d9",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Place all necessary imports here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e58eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "# For cleaner plots (optional), you can increase figure size defaults:\n",
    "# plt.rcParams['figure.figsize'] = (8, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04736ea",
   "metadata": {},
   "source": [
    "# Section 1: Import and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da423c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Load the Titanic dataset\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# Display basic information\n",
    "titanic.info()\n",
    "\n",
    "# Display the first 10 rows\n",
    "display(titanic.head(10))\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\\n\", titanic.isnull().sum())\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary Statistics:\\n\", titanic.describe())\n",
    "\n",
    "# Check for correlations (numeric only)\n",
    "print(\"\\nCorrelation Matrix (numeric only):\\n\", titanic.corr(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c55d8e9",
   "metadata": {},
   "source": [
    "### Reflection 1\n",
    "1. How many data instances are there? 891\n",
    "2. How many features are there? 15\n",
    "3. What are the names of the features? survived, pclass, sex, age, sibsp, parch, fare, embarked, class, who, adult_male, deck, embark_town, alive, alone\n",
    "4. Are there any missing values? age, embark_town, and sometimes deck have missing values.\n",
    "5. Are there any non-numeric features? sex, embarked, class, who, deck, embark_town, alive, and alone\n",
    "6. Are the data instances sorted on any attribute? Doesn't seem to be\n",
    "7. What are the units of `age`? Years\n",
    "8. What are the minimum, median, and maximum age values? Min is .42 median is 28 and max is 28.\n",
    "9. Which two numeric features have the highest correlation? fare and pclass\n",
    "10. Are there any categorical features that might be useful for prediction? Yes, sex, pclass and embarked\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6c790b",
   "metadata": {},
   "source": [
    "# Section 2: Data Exploration and Preparation\n",
    "\n",
    "## 2.1 Explore Data Patterns and Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0bac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Matrix for numeric attributes\n",
    "attributes = ['age', 'fare', 'pclass']\n",
    "scatter_matrix(titanic[attributes], figsize=(10,10))\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot of age vs fare, colored by sex (male=0, female=1)\n",
    "plt.scatter(\n",
    "    titanic['age'], \n",
    "    titanic['fare'], \n",
    "    c=titanic['sex'].apply(lambda x: 0 if x == 'male' else 1)\n",
    ")\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Fare')\n",
    "plt.title('Age vs Fare by Gender')\n",
    "plt.show()\n",
    "\n",
    "# Histogram of age\n",
    "sns.histplot(data=titanic, x='age', kde=True)\n",
    "plt.title('Age Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Countplot for class, hue by survived\n",
    "sns.countplot(x='class', hue='survived', data=titanic)\n",
    "plt.title('Class Distribution by Survival')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf70ff90",
   "metadata": {},
   "source": [
    "### Reflection 2.1\n",
    "- What patterns or anomalies do you notice? Fare values have a very large range\n",
    "- Do any features stand out as potential predictors? sex and pclass seem important, which makes sense since we know first class and women survived more.\n",
    "- Are there any visible class imbalances? With survived, we have more people who did not survive compared to who those who, shows a bit of an imbalance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca98ab",
   "metadata": {},
   "source": [
    "## 2.2 Handle Missing Values and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing Age with median\n",
    "titanic['age'].fillna(titanic['age'].median(), inplace=True)\n",
    "\n",
    "# Fill missing embark_town with mode\n",
    "titanic['embark_town'].fillna(titanic['embark_town'].mode()[0], inplace=True)\n",
    "\n",
    "# Check if still any missing\n",
    "print(\"Missing Values After Cleaning:\\n\", titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f9a2a",
   "metadata": {},
   "source": [
    "## 2.3 Feature Engineering\n",
    "Create additional or transformed features, as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b13745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature: family_size = sibsp + parch + 1\n",
    "titanic['family_size'] = titanic['sibsp'] + titanic['parch'] + 1\n",
    "\n",
    "# Convert 'sex' to numeric\n",
    "titanic['sex'] = titanic['sex'].map({'male':0, 'female':1})\n",
    "\n",
    "# Convert 'embarked' to numeric\n",
    "titanic['embarked'] = titanic['embarked'].map({'C':0, 'Q':1, 'S':2})\n",
    "\n",
    "# Optional: Make 'alone' an integer\n",
    "titanic['alone'] = titanic['alone'].astype(int)\n",
    "\n",
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bec4c34",
   "metadata": {},
   "source": [
    "### Reflection 2.3\n",
    "- Why might `family_size` be a useful feature for predicting survival? It will show if a having a large family can slow you down\n",
    "- Why convert categorical data to numeric? Most machine learning concepts require numeric inputs\n",
    "\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89db6c62",
   "metadata": {},
   "source": [
    "# Section 3: Feature Selection and Justification\n",
    "Pick which features to use as predictors (X) and which to use as target (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb5d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For classification, let's pick some columns\n",
    "X = titanic[['age', 'fare', 'pclass', 'sex', 'family_size']]\n",
    "y = titanic['survived']  # 0 or 1\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf511efa",
   "metadata": {},
   "source": [
    "### Reflection 3\n",
    "- Why did you pick these features? I picked these because I thought they would be critical for survival.\n",
    "- Which do you suspect will be highly predictive? I think sex and pclass will be. We know that women and children and first class survived the most.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7294bca",
   "metadata": {},
   "source": [
    "# Section 4: Splitting the Data\n",
    "We'll do both a basic train/test split and a stratified train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da5263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Basic Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=123\n",
    ")\n",
    "print('Basic Split =>')\n",
    "print('Train size:', len(X_train), 'Test size:', len(X_test))\n",
    "\n",
    "# Check distribution of the target in the train/test sets\n",
    "print('\\nOriginal Survived Dist:', y.value_counts(normalize=True))\n",
    "print('Train Survived Dist:', y_train.value_counts(normalize=True))\n",
    "print('Test Survived Dist:', y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5328ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Stratified Train/Test Split\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=123)\n",
    "\n",
    "for train_idx, test_idx in splitter.split(X, y):\n",
    "    X_train_strat = X.iloc[train_idx]\n",
    "    y_train_strat = y.iloc[train_idx]\n",
    "    X_test_strat = X.iloc[test_idx]\n",
    "    y_test_strat = y.iloc[test_idx]\n",
    "\n",
    "print('\\nStratified Split =>')\n",
    "print('Train size:', len(X_train_strat), 'Test size:', len(X_test_strat))\n",
    "\n",
    "# Check distribution of the target in the stratified train/test sets\n",
    "print('\\nOriginal Survived Dist:', y.value_counts(normalize=True))\n",
    "print('Strat Train Survived Dist:', y_train_strat.value_counts(normalize=True))\n",
    "print('Strat Test Survived Dist:', y_test_strat.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec8f6a9",
   "metadata": {},
   "source": [
    "### Reflection 4\n",
    "- Why might stratification improve model performance? It makes that test sets have the same proportion for survivors vs non-survivors\n",
    "- Which split method produced a class distribution closer to the original? The stratisfied split kept the original ratio of survivors to non-survivors more precise\n",
    "- In what scenarios might stratification be less important? If the dataset is already large and balanced beforehand.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ae7c0",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "First, I checked out all the info in the dataset and saw there were some missing values, especially in age. I filled those in, and then poked around the data with some basic plots, noticing stuff like how class and gender seemed tied to survival. It was actually kind of interesting to see real historical patterns in the numbers.\n",
    "\n",
    "I also created a new column, family_size, to see if traveling in a group might matter for survival, and then converted any non-numerical columns (like sex and embarked) into numbers so that future machine learning models can use them. After cleaning everything up, I split the data two ways: a regular train/test split and a stratified split. The stratified split makes sure the survival rate stays about the same in both training and testing sets, which should help the final models perform more accurately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
